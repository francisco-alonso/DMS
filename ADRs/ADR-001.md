# ADR-001: Selection of Landmark Extraction Framework for Phase 1  
**Status:** Accepted  
**Date:** 2025-12-06 
**Author:** Francisco Lopez

---

## 1. Context

In Phase 1 of the Driver Monitoring System (DMS), we need a reliable and efficient way to extract **facial landmarks** from frames captured by the webcam.

These landmarks will be used to compute key metrics such as:

- **EAR (Eye Aspect Ratio)** for drowsiness  
- **MAR (Mouth Aspect Ratio)** for yawning  
- **Head pose (yaw, pitch, roll)** for distraction  
- (Future) **Gaze estimation**

The chosen system must run:

- **in real time (>15 FPS)**  
- **on CPU (Mac)**  
- **with minimal installation complexity**  
- **with high landmark quality and robustness**  

This will serve as the foundation of the entire multi-phase project, including later edge-AI deployment and microservices integration.

---

## 2. Problem

We need a **landmark extraction method** that:

1. Works well on macOS without GPU  
2. Provides sufficiently detailed landmarks for accurate EAR/MAR  
3. Is easy to integrate into a prototype  
4. Can process video frames in real time  
5. Can scale toward more advanced models later  
6. Minimizes initial complexity so we can focus on pipeline architecture

Without a reliable landmark detector, **no downstream logic (EAR/MAR/decision engine) is possible.**

---

## 3. Options Considered

### **Option 1 — MediaPipe FaceMesh**
- 468 3D landmarks (x, y, z)  
- Excellent eyelid/iris/mouth resolution  
- Real-time CPU performance  
- Easy installation (`pip install mediapipe`)  
- Highly robust to lighting variations  
- Actively supported by Google  

### **Option 2 — dlib (68-point model)**
- Classical, widely used  
- Gives fewer landmarks (only 68)  
- Not ideal for precise eyelid modeling  
- Harder installation on macOS  
- Slower and less robust in low light  

### **Option 3 — Custom-trained model**
- Maximum flexibility  
- Potential for highest accuracy  
- But requires dataset, labeling, training pipeline  
- Too heavy for Phase 1  
- Only suitable much later (Phase 3+)

---

## 4. Decision

**Use MediaPipe FaceMesh as the landmark extraction system for Phase 1.**

This decision applies to:
- Phase 1 (prototype)  
- Phase 2 (feature expansion)  

Future phases (Phase 3+) may evaluate custom ONNX/TensorRT models for deployment on Jetson or equivalent hardware.

---

## 5. Rationale — Why MediaPipe Solves Our Problem

### **Problem 1: Need accurate eyelid geometry for EAR**
MediaPipe provides **high-resolution eye and iris landmarks**, enabling stable EAR measurement.

### **Problem 2: Need fast inference on CPU**
MediaPipe FaceMesh is optimized for **real-time CPU execution**.

### **Problem 3: Need minimal complexity**
Installation is trivial, avoiding dlib’s build issues.

### **Problem 4: Need depth-like cues for head pose**
MediaPipe provides **(x, y, z)** coordinates, improving head-pose estimation.

### **Problem 5: Need scalability**
We can replace MediaPipe later with:
- ONNX models  
- TensorRT-optimized models  
- Custom CNNs  

without changing the pipeline architecture, because the interface (landmarks → features → decision) remains the same.

### **Problem 6: Need robustness**
MediaPipe handles:
- partial occlusions  
- glasses  
- moderate lighting variation  
better than dlib.

---

## 6. Consequences

### **Positive**
- Faster development  
- Higher accuracy landmarks  
- Real-time performance on any computer  
- Clean integration into early pipeline  
- Easier debugging and calibration  
- Allows quick iteration on EAR/MAR thresholds  

### **Negative**
- Less control over internal model parameters  
- Harder to retrain compared to custom models  
- MediaPipe is not automotive-certified  
- May require replacement in real deployment stages  

---

## 7. Future Considerations

In Phases 3–4, we evaluate:
- Lightweight CNN landmark models  
- BlazeFace + custom regression head  
- ONNXRuntime / TensorRT inference  
- Ability to deploy on Jetson or ARM SBCs  

But only after the Phase 1/2 system is functioning end-to-end.

---

## 8. Decision Outcome

**MediaPipe FaceMesh is selected as the Phase 1 landmark extraction engine** because it offers the best balance of performance, ease of use, robustness, and alignment with learning goals.

This ADR closes the choice for perception-layer modeling in the early phases of the project.

